#+title: moc
#+subtitle: Model Oriented Configuration
#+setupfile: setup.org
#+options: broken-links:mark


* Overview
  :PROPERTIES:
  :CUSTOM_ID: overview
  :END:


moc is a moo for a /configuration/ system.  It provides::

- a vocabulary for defining the /schema/ that configuration information should follow.

- tooling to validate configuration objects against their schema.

- code generators creating native language (C++/Python) types and serialization methods between those types and configuration objects.

- native language libraries and shell programs for producing and consuming configuration in a variety of /formats/ and media including files and /streams/.

- a demo application and configuration.

* Dive in
  :PROPERTIES:
  :CUSTOM_ID: dive-in
  :END:

moc is currently not production but rather provides a mock up demo.
To use it, first install the ~moo~ Python package eg like:

#+begin_example
  $ echo layout python3 > .envrc
  $ direnv allow
#+end_example

Or, if you don't have ~direnv~

#+begin_example
  $ python3 -m venv venv
  $ source venv/bin/activiate
#+end_example

Then install ~moo~

#+begin_example
  $ pip install -e .
  $ moo --help
#+end_example

The moc demo is in [[file:moc/][moc/]]:

#+begin_example
  $ cd moc
  $ make
#+end_example


* Technical design
  :PROPERTIES:
  :CUSTOM_ID: technical-design
  :END:

moc is a *moo* focused on generating configuration objects and various means to deliver them into an application.  This section describes aspects of the technical design.

** Streams, frames and messages
   :PROPERTIES:
   :CUSTOM_ID: stream-frame-message
   :END:

moc configuration data follows an abstract low level format which may be realized in a few ways and independently from the concrete high level schema of the delivered content.  This provides flexibility to an application to select how configuration information is delivered  

The abstract low level format is defined in terms of *streams* of *bytes*, *frames* and *messages* as described:

- bytes :: A *moc byte stream* consists of a sequence of 8 bit bytes.  Several types of byte streams are supported by moc including commonly known ones (eg, a JSON object or a [[https://en.wikipedia.org/wiki/JSON_streaming][JSON stream]] and ones suitable for message passing systems like ZeroMQ).  Some byte streams may place limits the format of information they carry (eg, a JSON Stream may be used only for JSON text).

- frames :: A *moc frame stream* consists of a logical sequence of frames derived from a bytes stream.  A frame is a contiguous and finite sequence of bytes which may be read into memory in an atomic manner.  If two byte streams support the format of a frame then they both shall decode an identical frame identically.  

- messages :: A *moc message stream* consists of a logical sequence of messages derived from a frame stream.  The application may determine the extent and interpretation of the message by progressively examining the frames.  moc messages must have an initial frame, called the message type *hint* which must consist of only printable ASCII characters suitable for use in forming a C symbol.  moc reserves a number of hint values, listed in the table below which are to be used to identify the low-level format of the next and last frame in the message called the *payload*.  The application is free to extend the list of message type hints it supports.

- types :: A *moc type stream* produces a stream of objects in native language type.  It serializes messages from a moc message stream.  When used, the application must know the type expected.

** Reserved message types
   :PROPERTIES:
   :CUSTOM_ID: message-types
   :END:

The set of reserved moc message type hints are:

|------+------------------+-----+--------|
| hint | payload encoding | C++ | Python |
|------+------------------+-----+--------|
| JSON | JSON string      | yes |        |
| BSON | Binary JSON      | yes |        |
| CBOR | Binary JSON      | yes |        |
| UBJS | Binary JSON      | yes |        |
| MSGP | Message Pack     | yes |        |
| JSNT | Jsonnet string   |     |        |
| AVRJ | Avro JSON        |     |        |
| AVRB | Avro binary      |     |        |
| PBUF | Protobuf         |     |        |
|------+------------------+-----+--------|

** Byte stream formats
   :PROPERTIES:
   :CUSTOM_ID: byte-stream-formats
   :END:


moc provides byte stream decoding for a few common types:

- JSON :: the bytes stream is assumed to be a [[https://en.wikipedia.org/wiki/JSON_streaming][JSON stream]].  As it may only hold JSON format data the moc message type hint is implicitly and always ~JSON~.  The stream may consist of an admixed concatenation of JSON types.  The first frame from a JSON byte stream is the string ~JSON~ which is implicitly generated.  The second frame will contain the JSON text of the first JSON type in the stream.  This then repeats until the stream is exhausted.  An trivial example of a JSON stream with a sequence of JSON objects:

#+begin_src json
{"greeting":"hi"}{"greeting":"bye"}
#+end_src

- SHFM :: a "size-hinted framed message" may hold arbitrary data (binary and text, including JSON) and is well suited for use with ZeroMQ or other message passing systems.  In the byte stream, a frame is prefixed with a binary value holding the size of the frame data measured in bytes.  If less than 255 the size value is stored in a single byte.  If the size is 255 or greater but less than 2^32-1 the first byte is 255 (~0xff~) and the next four bytes hold the size as a 32 bit integer.  The first frame in a message shall provide the message type hint and for hints reserved by moc, the subsequent and only other frame in the message holds the payload frame of that type.  An example SHFM message is shown next with a frame depicted as ~[ size | body ]~ where the ~size~ in a binary value and the ~body~ is expressed in ASCII:

#+begin_example
[ 4 | JSON ][ 8 | {"a":42} ]
#+end_example

** Schema
   :PROPERTIES:
   :CUSTOM_ID: schema
   :END:

When using reserved message types, the moc library can transparently handle a choice of both the byte stream (among the supported formats) and of low-level frame data format (ie, JSON vs Avro, etc).   The producer and consumer of a moc *message stream* must honor a shared *contract* which governs the structure of the data at three semantic layers:

- payload :: the structure of information in given payload frame (format is handled by moc)
- intra message :: the structure of payload frames in a message (if using custom message types, moc reserved types only have one frame).  
- inter message :: the number, structure, order and interpretation of messages in a stream.

moc provides some means to rigorously define the contract, particularly as it pertains to payload structure.  This part of the contract is in the form of *schema*.  A schema is a (meta) data structure that describes the "shape" of other data structure.  There are two goals in mind for the use of a schema:

- validation :: a schema may be used to check if a given data structure, aka "object" aka *model*, obeys the contract defined by the schema.
- generation :: a schema may be applied to a *template* in order to generate a *representation*, usually in a source code language (C++/Python) but also documentation, diagram markup language, etc. 

For practical reasons, we want to represent a conceptual or abstract schema in two (or more) different forms.  For example, JSON Schema vocabulary is well suited for validation schema while Avro Schema is well suited for generation schema.

We would like to avoid manually crafting and keeping consistent two (or more) separate representations.  To save us, moc provides sets of Jsonnet functions.  Each set returns fundamental schema data structure of a particular vocabulary (eg, JSON Schema or Avro schema).  A developer of a moc configuration may then write a set of high level functions parameterized by a fundamental function set and then structures in all supported schema vocabulary may be generated.

This may seem complex but in practice it is simple as described in the example in the next section.

** Example schema
   :PROPERTIES:
   :CUSTOM_ID: example-schema
   :END:


A simple example makes this clear.  As described above, moc reserves a set of message type hints.  We may define schema for this simple frame like:

#+include: moc/simple.jsonnet src jsonnet

With the above, ~moo~ can validate that ~data~ is correct against ~jscm~:

#+begin_src shell :exports both :results output code :wrap "example"
moo validate -s moc/simple.jsonnet -S jscm -D data moc/simple.jsonnet
#+end_src

#+RESULTS:
#+begin_example
null
#+end_example

The null means no error.

We may use ~moo~ to compile the ~avro~ structure to an Avro schema JSON file and generate code:

#+begin_src shell :exports both :results output code :wrap "src c++"
moo compile -P avro moc/simple.jsonnet > simple.json
avrogencpp -n moc -i simple.json -o simple_avro.hpp
grep -m1 -A10 Hint: simple_avro.hpp
#+end_src

#+RESULTS:
#+begin_src c++
enum class Hint: unsigned {
    JSON,
    BSON,
    CBOR,
    UBJS,
    MSGP,
    JSNT,
    AVRJ,
    AVRB,
    PBUF,
};
#+end_src

In that header is more generated code to serialize this ~enum~ via the Avro codec.  moc may provide methods to transparently select that codec based on the "hint" being ~AVRJ~ or ~AVRB~.

moc also supports ~nlohmann::json~ family of codecs to support the remaining hints besides ~PBUF~.  With a suitable template file and the info supplied in the model by the ~tmpl~ attribute, ~moo~ can generate the needed code like:

#+begin_src shell :exports both :results output code :wrap "src c++"
moo render -P tmpl moc/simple.jsonnet moc/avro_nljs.hpp.j2 > simple_nljs.hpp
grep -m1 -A10 ENUM simple_nljs.hpp
#+end_src

#+RESULTS:
#+begin_src c++
    NLOHMANN_JSON_SERIALIZE_ENUM( Hint, {
            { moc::Hint::JSON, "JSON" },
            { moc::Hint::BSON, "BSON" },
            { moc::Hint::CBOR, "CBOR" },
            { moc::Hint::UBJS, "UBJS" },
            { moc::Hint::MSGP, "MSGP" },
            { moc::Hint::JSNT, "JSNT" },
            { moc::Hint::AVRJ, "AVRJ" },
            { moc::Hint::AVRB, "AVRB" },
            { moc::Hint::PBUF, "PBUF" },
        })
#+end_src

Where this snippet shows how we ultimately rely on a CPP macro provided by ~nlohmann~ to generate codec.  This produces ~to_json()~ and ~from_json()~ type functions.

** Payload schema
   :PROPERTIES:
   :CUSTOM_ID: payload-schema
   :END:


The simple example above may be considered also an example of a trivial payload body schema.  However, a payload schema will typically be rather more complex.  It will be built from various primitive schema types as well as built up further upon types it defines itself.  For example, consider a schema describing the simple object example from [[https://github.com/nlohmann/json/#arbitrary-types-conversions][nlohmann::json]] documentation:

#+include: moc/person.jsonnet src jsonnet

The fundamental types provided by moo are an amalgamation of those named by Avro and JSON Schema: ~boolean~, ~string~, ~number~, ~array~ of a type and ~record~ aggregating a number of ~field~ elements, each of a type.  

** Intra-message Schema
   :PROPERTIES:
   :CUSTOM_ID: intra-message
   :END:


The message type hints reserved by moc also specify exactly one message payload frame may follow.  The intra-message schema for these types is thus specified.

Application developers are free to extend the supported hints to include message types with multiple payload frames.  They may develop schema to describe the message as a hole in terms of an array of schema.  

For example, an application may prefer define a "PEOPLE" message type which puts in each frame a ~person~ record as described in the example above.  An intra-message schema may then be defined as the ~people~ schema.  What is required in the Jsonnet is to expose more of the internal schema structure for example as:

#+begin_src jsonnet
  // as above
  {
      schema(s):: {
          // [...as above omitted...]
          // person
          people: s.array(self.person),
      }
      jscm: self.schema(j.schema).people,
      avro: self.schema(a.schema).people,
  }
#+end_src

Note we comment out the "return value" ~person~ and instead use its local definition as a type to define the returned ~people~.

The same document may produce JSON Schema and Avro schema for all abstract schema:

#+begin_src jsonnet
  {
      schema(s) :: {
          // locals as above but return object of:
          person: person,
          people: people,
      }
      jscm: self.schema(j.schema),
      avro: self.schema(a.schema),
  }
#+end_src

When applying either of the produced schema one has to take into account the substructure.  Eg, ~avro.person~ would be used to generate a ~Person~ object.

** Inter-message schema
   :PROPERTIES:
   :CUSTOM_ID: inter-message
   :END:

Inter-message schema may be (under) specified simply as an array of expected hints.   Or the same patterns described above may be extended to cover multiple messages as they are shown to cover multiple frames.  In other words, it may be schema all the way down.  


* Demos

moc provides a few demo uses.  

** Install prerequisites

The demo requires:

- the ~moo~ Python command line program in ~$PATH~
- the Avro C++ library and ~avrogencpp~ in ~$PATH~
- ~make~, compiler, etc

** Run the demo
   :PROPERTIES:
   :CUSTOM_ID: run-the-demo
   :END:

The demos can be built and exercised with:

#+begin_src shell :exports both :results output code :wrap "example"
cd moc && make clean all
#+end_src

#+RESULTS:
#+begin_example
rm -f demo demo.log demo-config.json node_avro.hpp demo_avro.hpp node_nljs.hpp demo_nljs.hpp
moo compile -P avro node.jsonnet > node_avro.json
avrogencpp -n moc -i node_avro.json -o node_avro.hpp
moo compile -P avro demo.jsonnet > demo_avro.json
avrogencpp -n moc -i demo_avro.json -o demo_avro.hpp
moo render -P nljs node.jsonnet avro_nljs.hpp.j2 > node_nljs.hpp
moo render -P nljs demo.jsonnet avro_nljs.hpp.j2 > demo_nljs.hpp
g++  -ggdb3 -std=c++17 -Wall -o demo demo.cpp \
           -I ../inc -I. -I/home/bv/opt/avro/include -L/home/bv/opt/avro/lib -lavrocpp -Wl,-rpath=/home/bv/opt/avro/lib
moo compile --string -P demo.stream demo.jsonnet > demo-config.json
./demo demo-config.json > demo.log
cat demo.log
Factory: MySource instance mysource1
Creating new SourceComponent
SourceComponent mysource1 configuring
	ntosend = 10
Factory: Node instance mynode1
Creating new Node
Config for moc::Node ID: "mynode1"
	node port ID: "src"
		link type:0 address:""
	node comp type "MySource" instance "mysource1" wants port IDs: "src"
		instance config: "MySource::mysource1 config string"
Factory: MySource instance mysource1
Have MySource instance mysource1
Source mysource1 using ports: src
configure done
rm node_avro.json demo_avro.json
#+end_example

This automatically does the following:

- generates schema objects from Jsonnet
- applies those schema objects to generate Avro schema files
- generates C++ classes with Avro's C++ generator
- augments the C++ classes with functions to serialize to/from ~nlohmann::json~
- builds a demo ~main()~ program with generated and hand-written code.
- produces schema-compliant configuration objects as JSON stream files
- runs the demo to process the streams using moc's C++ support code

** Demo framework
   :PROPERTIES:
   :CUSTOM_ID: demo-framework
   :END:

The demo utilizes a simple application framework called *moc node* which mocks up (really, mocks down) a full featured implementation found as [[https://brettviren.github.io/zio/node.html][ZIO node]].  It is used to provide a realistic target for configuration.  moc node differs from ZIO node in that the factory/plugin pattern is fake and no actual port initialization, discovery, auto-connect or other ZIO mechanisms are implemented.  Instead, the demo constructs via the fake factory and applies configuration merely by printing out its values.

Nonetheless, the moc node framework is faithful to the type of configuration complexity that would be required to use ZIO node or similar application aggregation concepts.  The demo application is deconstructed into these parts:

- node :: represents a unit of functionality to the system and is composed of *ports* and *components*
- port :: an abstraction of a message passing socket.  It is through ports that a node, via its *components* interacts with the outside world.
- component :: a unit of application functionality.  Components may use and share zero or more ports created by the node.

Components instances are addressed by a pair of names as strings: type or implementation name and instance name.  In C++ code, an instance is held by an abstract base class aka an interface class.  In a real framework, a factory/plugin method would be used to dynamically local code for a component from a set of shared libraries and dynamically construct and later allow lookup of instances.  The moc demos will fake that but the (implementation,instance) name pairs are still used in the configuration.

Given this deconstruction, any number of nodes may be created in the ~demo~ main program and in each node any number of components may be created.  Each node "makes" a number of ports, handles their (fake) bind/connect and is told which components wish to utilize which ports.  This is all driven by configuration which itself is governed by schema.

** Demo details

This section highlights some of the details in the code.  First
the [[file:moc/Makefile][Makefile]] drives the entire demo and then the [[file:moc/demo.cpp][demo.cpp]] ~main()~ program.

*** Makefile driver

The demo uses a Makefile to automate the demo.  The source is a few Jsonnet files, a hand-written header and a hand written ~main()~.  All the rest is generated.

To start, we directly compile Jsonnet structure to AVRO schema JSON and run the ~avrogencpp~ program to generate C++ header files defining C++ structs which will match our configuration objects.  We take the convention to put these generated files in ~<name>_avro.hpp~ where the name may be ~node~ for common "framework" classes and ~demo~ for application classes:

#+begin_src shell :exports both :results output code :wrap "src makefile"
grep -m1 -A4 demo:AVRO moc/Makefile
#+end_src

#+RESULTS:
#+begin_src makefile
# demo:AVRO schema and generate C++ 
%_avro.json: %.jsonnet 
	moo compile -P avro $< > $@
%_avro.hpp: %_avro.json
	$(AVROGENCPP) -n $(namespace) -i $< -o $@
#+end_src

Next, we directly apply another part of the Jsonnet structures via ~moo~ to a template to generate ~nlohmann::json~ (NLJS) serialization functions for the Avro classes.  

#+begin_src shell :exports both :results output code :wrap "src makefile"
grep -m1 -A2 demo:NLJS moc/Makefile
#+end_src

#+RESULTS:
#+begin_src makefile
# demo:NLJS generated C++ 
%_nljs.hpp: %.jsonnet avro_nljs.hpp.j2 
	moo render -P nljs $^ > $@
#+end_src

Last we show how one particular configuration may be generated.  In a real system we might keep the Jsonnet files for configuration separate from code generation, maybe managed in ~git~.  Or, some configuration information may start as Jsonnet or other forms, go into some "database" and be derived to form the JSON or SHFM streams.

#+begin_src shell :exports both :results output code :wrap "src makefile"
grep -m1 -A2 demo:config moc/Makefile
#+end_src

#+RESULTS:
#+begin_src makefile
# demo:config generated configuration data
demo-config.json: demo.jsonnet
	moo compile --string -P demo.stream demo.jsonnet > demo-config.json
#+end_src

Note the use of ~--string~ which produces a JSON Stream format instead of a JSON array.

*** Mock application

The file [[file:moc/demo.cpp][demo.cpp]] holds code to fake an entire software application framework and fakes several services and application level components.  Let us start in ~main()~ with creation of the configuration stream:

#+begin_src shell :exports both :results output code :wrap "src c++"
grep -m1 -A3 demo:main moc/demo.cpp
#+end_src

#+RESULTS:
#+begin_src c++
    // demo:main
    std::ifstream fstr(streamname);
    moc::type_stream ts = moc::make_type_stream(fstr, streamtype);
    do_configure(ts);
#+end_src

In a real application we might hide the details of where the bytestream comes from by placing this code in a configuration manager and have different manager for, eg files as ZeroMQ messages.  Next we see ~do_configure()~:

#+begin_src shell :exports both :results output code :wrap "src c++"
grep -m1 -A16 do_configure moc/demo.cpp
#+end_src

#+RESULTS:
#+begin_src c++
void do_configure(moc::type_stream& ts)
{
    while (true) {
        moc::ConfigHeader ch;
        try {
            ch = ts.pop<moc::ConfigHeader>();
        }
        catch (std::runtime_error(re)) {
            // fixme: mock: find a less dramatic way to signal end of stream
            std::cout << "configure done\n";
            return;
        }

        auto& ic = fake_factory<IConfigurable>(ch.impname, ch.instname);
        ic.configure(ch.instname, ts);
    }
}
#+end_src

Here we see how the ~moc::type_stream~ can "retype" the underlying byte stream using the generated. Avro classes and NLJS serialization functions. 

The ~do_configure()~ enacts a particular protocol for applying the configuration stream to the application.  This is an example of an *inter-message schema* described above.  It requires message stream come with messages like

1. ~ConfigHeader~
2. configuration body
3. ~ConfigHeader~
4. configuration body
5. ...

The ~moc::ConfigHeader~ is ultimately defined by:

#+begin_src shell :exports both :results output code :wrap "src jsonnet"
grep -m1 -A1 ConfigHeader moc/demo.jsonnet
#+end_src

#+RESULTS:
#+begin_src jsonnet
        local cfghdr = s.record("ConfigHeader", fields=[
            s.field("impname", ident), s.field("instname", ident)]),
#+end_src

And, it is the  *implementation name* (~impname~) and *instance name* (~instname~) which are used by the factory method in ~demo.cpp~ to look up an appropriate instance to consume the subsequent *configuration body*.

The first configuration in the demo goes to an instance of a ~SourceComponent~ named ~mysource1~.  It's not a very interest class but just not that it is configured first.  The next configurable is a ~Node~ instance.  ~Node~ is considered a "framework" level class while ~SourceComponent~ may be a class provided in a plugin library.  In ZIO a "node" would be an atomic unit "known" to the outside world via ZeroMQ sockets and Zyre discovery.  Most likely we will have one node for each executable, but there is no technical limitation.

The moc demo node is useful to look at to see how it also uses the factory to get an interface to a component so that it may pass on *port* objects.  In the demo, ports are simply strings.  In equivalent ZIO code, ports hold sockets which are bind/connect via configuration.

#+begin_src shell :exports both :results output code :wrap "src c++"
grep -m1 -A3 demo:lookup moc/demo.cpp
#+end_src

#+RESULTS:
#+begin_src c++
             // demo:lookup
             auto& ip = fake_factory<IPorted>(compcfg.type_name, compcfg.ident);
             ip.set_ports(ps);
         }
#+end_src

